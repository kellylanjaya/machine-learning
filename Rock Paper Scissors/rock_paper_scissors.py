# -*- coding: utf-8 -*-
"""Rock Paper Scissors

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QbK5miZFbcji-7iHPXyNdSMTztiTUR6U
"""

!wget --no-check-certificate \
  https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip \
  -O /tmp/rockpaperscissors.zip

import zipfile
import os
import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
import numpy as np
from google.colab import files
from keras.preprocessing import image
import matplotlib.pyplot as plt
import matplotlib.image as mpimg

local_zip = '/tmp/rockpaperscissors.zip'
base_dir = '/tmp/rockpaperscissors/rps-cv-images'
zip_extract = zipfile.ZipFile(local_zip, 'r')
zip_extract.extractall('/tmp')
zip_extract.close()

train_datagen = ImageDataGenerator(horizontal_flip = True, fill_mode = 'wrap', rescale = 1./255, rotation_range = 20,  shear_range = 0.2, validation_split = 0.4)
train_generator = train_datagen.flow_from_directory(base_dir, target_size = (100, 150), class_mode = 'categorical', subset = 'training')
validation_generator = train_datagen.flow_from_directory(base_dir, target_size = (100, 150), class_mode = 'categorical', subset = 'validation')

model = tf.keras.models.Sequential([
    tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu', input_shape = (100, 150, 3)),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(128, (3, 3), activation = 'relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Conv2D(256, (3, 3), activation = 'relu'),
    tf.keras.layers.MaxPooling2D(2, 2),
    tf.keras.layers.Flatten(),
    tf.keras.layers.Dense(512, activation = 'relu'),
    tf.keras.layers.Dense(3, activation = 'softmax')
])

model.compile(loss = 'categorical_crossentropy', optimizer = tf.optimizers.Adam(), metrics = ['accuracy'])

accuracy_threshold = 98e-2

class my_callbacks(tf.keras.callbacks.Callback):
    def on_epoch_end(self, epoch, logs = None):
        if logs.get('accuracy') >= accuracy_threshold:
            print('\nFor Epoch', epoch, '\nAccuracy has reach = %2.2f%%' %(logs['accuracy']*100), 'training has been stopped.')
            self.model.stop_training = True

history = model.fit(train_generator, steps_per_epoch = 25, epochs = 20, validation_data = validation_generator, validation_steps = 5, verbose = 2, callbacks = [my_callbacks()])

# Commented out IPython magic to ensure Python compatibility.
# %matplotlib inline

uploaded = files.upload()

for fn in uploaded.keys():
    path = fn
    img_source = image.load_img(path, target_size = (100, 150))
    imgplot = plt.imshow(img_source)
    x = image.img_to_array(img_source)
    x = np.expand_dims(x, axis = 0)

    images = np.vstack([x])
    classes = model.predict(images, batch_size = 10)

    print(fn)
    if classes[0, 0] == 1:
      print('rock')
    elif classes[0, 1] == 1:
      print('paper')
    elif classes[0, 2] == 1:
      print('scissors')